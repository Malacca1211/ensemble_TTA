[24/04/19 11:28:27] [conf.py:  213]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: tent_Adam_0.0001_bs200_em0.2.txt
LOG_TIME: 240419_112827
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 0.0001
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RESET_CONSTANT_EM: 0.2
RNG_SEED: 1
SAVE_DIR: ./output2
TEST:
  BATCH_SIZE: 200
[24/04/19 11:28:27] [cifar10c_all_resemble.py:  120]: test-time adaptation: TENT
[24/04/19 11:28:27] [cifar10c_all_resemble.py:  442]: model for adaptation: DataParallel(
  (module): ResNet_SDN(
    (init_conv): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0-8): 9 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (9): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (10): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (11): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (12-14): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (15): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (16-17): 2 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (18): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (19): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (20-22): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (23): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (24-26): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
    )
    (end_layers): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)
      (1): Flatten()
      (2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)
[24/04/19 11:28:27] [cifar10c_all_resemble.py:  443]: params for adaptation: ['module.init_conv.1.weight', 'module.init_conv.1.bias', 'module.layers.0.layers.0.1.weight', 'module.layers.0.layers.0.1.bias', 'module.layers.0.layers.0.4.weight', 'module.layers.0.layers.0.4.bias', 'module.layers.1.layers.0.1.weight', 'module.layers.1.layers.0.1.bias', 'module.layers.1.layers.0.4.weight', 'module.layers.1.layers.0.4.bias', 'module.layers.2.layers.0.1.weight', 'module.layers.2.layers.0.1.bias', 'module.layers.2.layers.0.4.weight', 'module.layers.2.layers.0.4.bias', 'module.layers.3.layers.0.1.weight', 'module.layers.3.layers.0.1.bias', 'module.layers.3.layers.0.4.weight', 'module.layers.3.layers.0.4.bias', 'module.layers.4.layers.0.1.weight', 'module.layers.4.layers.0.1.bias', 'module.layers.4.layers.0.4.weight', 'module.layers.4.layers.0.4.bias', 'module.layers.5.layers.0.1.weight', 'module.layers.5.layers.0.1.bias', 'module.layers.5.layers.0.4.weight', 'module.layers.5.layers.0.4.bias', 'module.layers.6.layers.0.1.weight', 'module.layers.6.layers.0.1.bias', 'module.layers.6.layers.0.4.weight', 'module.layers.6.layers.0.4.bias', 'module.layers.7.layers.0.1.weight', 'module.layers.7.layers.0.1.bias', 'module.layers.7.layers.0.4.weight', 'module.layers.7.layers.0.4.bias', 'module.layers.8.layers.0.1.weight', 'module.layers.8.layers.0.1.bias', 'module.layers.8.layers.0.4.weight', 'module.layers.8.layers.0.4.bias', 'module.layers.9.layers.0.1.weight', 'module.layers.9.layers.0.1.bias', 'module.layers.9.layers.0.4.weight', 'module.layers.9.layers.0.4.bias', 'module.layers.9.layers.1.1.weight', 'module.layers.9.layers.1.1.bias', 'module.layers.10.layers.0.1.weight', 'module.layers.10.layers.0.1.bias', 'module.layers.10.layers.0.4.weight', 'module.layers.10.layers.0.4.bias', 'module.layers.11.layers.0.1.weight', 'module.layers.11.layers.0.1.bias', 'module.layers.11.layers.0.4.weight', 'module.layers.11.layers.0.4.bias', 'module.layers.12.layers.0.1.weight', 'module.layers.12.layers.0.1.bias', 'module.layers.12.layers.0.4.weight', 'module.layers.12.layers.0.4.bias', 'module.layers.13.layers.0.1.weight', 'module.layers.13.layers.0.1.bias', 'module.layers.13.layers.0.4.weight', 'module.layers.13.layers.0.4.bias', 'module.layers.14.layers.0.1.weight', 'module.layers.14.layers.0.1.bias', 'module.layers.14.layers.0.4.weight', 'module.layers.14.layers.0.4.bias', 'module.layers.15.layers.0.1.weight', 'module.layers.15.layers.0.1.bias', 'module.layers.15.layers.0.4.weight', 'module.layers.15.layers.0.4.bias', 'module.layers.16.layers.0.1.weight', 'module.layers.16.layers.0.1.bias', 'module.layers.16.layers.0.4.weight', 'module.layers.16.layers.0.4.bias', 'module.layers.17.layers.0.1.weight', 'module.layers.17.layers.0.1.bias', 'module.layers.17.layers.0.4.weight', 'module.layers.17.layers.0.4.bias', 'module.layers.18.layers.0.1.weight', 'module.layers.18.layers.0.1.bias', 'module.layers.18.layers.0.4.weight', 'module.layers.18.layers.0.4.bias', 'module.layers.18.layers.1.1.weight', 'module.layers.18.layers.1.1.bias', 'module.layers.19.layers.0.1.weight', 'module.layers.19.layers.0.1.bias', 'module.layers.19.layers.0.4.weight', 'module.layers.19.layers.0.4.bias', 'module.layers.20.layers.0.1.weight', 'module.layers.20.layers.0.1.bias', 'module.layers.20.layers.0.4.weight', 'module.layers.20.layers.0.4.bias', 'module.layers.21.layers.0.1.weight', 'module.layers.21.layers.0.1.bias', 'module.layers.21.layers.0.4.weight', 'module.layers.21.layers.0.4.bias', 'module.layers.22.layers.0.1.weight', 'module.layers.22.layers.0.1.bias', 'module.layers.22.layers.0.4.weight', 'module.layers.22.layers.0.4.bias', 'module.layers.23.layers.0.1.weight', 'module.layers.23.layers.0.1.bias', 'module.layers.23.layers.0.4.weight', 'module.layers.23.layers.0.4.bias', 'module.layers.24.layers.0.1.weight', 'module.layers.24.layers.0.1.bias', 'module.layers.24.layers.0.4.weight', 'module.layers.24.layers.0.4.bias', 'module.layers.25.layers.0.1.weight', 'module.layers.25.layers.0.1.bias', 'module.layers.25.layers.0.4.weight', 'module.layers.25.layers.0.4.bias', 'module.layers.26.layers.0.1.weight', 'module.layers.26.layers.0.1.bias', 'module.layers.26.layers.0.4.weight', 'module.layers.26.layers.0.4.bias']
[24/04/19 11:28:27] [cifar10c_all_resemble.py:  444]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.0
)
[24/04/19 11:28:34] [cifar10c_all_resemble.py:  284]: error % [gaussian_noise5]: 33.82%
[24/04/19 11:28:54] [cifar10c_all_resemble.py:  284]: error % [shot_noise5]: 31.31%
[24/04/19 11:29:00] [cifar10c_all_resemble.py:  284]: error % [impulse_noise5]: 39.60%
[24/04/19 11:29:07] [cifar10c_all_resemble.py:  284]: error % [defocus_blur5]: 16.99%
[24/04/19 11:29:13] [cifar10c_all_resemble.py:  284]: error % [glass_blur5]: 42.06%
[24/04/19 11:29:25] [cifar10c_all_resemble.py:  284]: error % [motion_blur5]: 20.16%
[24/04/19 11:29:39] [cifar10c_all_resemble.py:  284]: error % [zoom_blur5]: 24.64%
[24/04/19 11:29:44] [cifar10c_all_resemble.py:  284]: error % [snow5]: 30.32%
[24/04/19 11:29:51] [cifar10c_all_resemble.py:  284]: error % [frost5]: 36.39%
[24/04/19 11:29:57] [cifar10c_all_resemble.py:  284]: error % [fog5]: 33.86%
[24/04/19 11:30:17] [cifar10c_all_resemble.py:  284]: error % [brightness5]: 28.22%
[24/04/19 11:30:23] [cifar10c_all_resemble.py:  284]: error % [contrast5]: 38.64%
[24/04/19 11:30:29] [cifar10c_all_resemble.py:  284]: error % [elastic_transform5]: 56.39%
[24/04/19 11:30:35] [cifar10c_all_resemble.py:  284]: error % [pixelate5]: 60.39%
[24/04/19 11:30:48] [cifar10c_all_resemble.py:  284]: error % [jpeg_compression5]: 67.65%
[24/04/19 11:30:48] [cifar10c_all_resemble.py:  287]: error % [mean5]: 37.36%
