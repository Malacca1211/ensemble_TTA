[24/04/19 11:32:00] [conf.py:  213]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: tent_Adam_1e-05_bs200_em0.2.txt
LOG_TIME: 240419_113200
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 1e-05
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RESET_CONSTANT_EM: 0.2
RNG_SEED: 1
SAVE_DIR: ./output2
TEST:
  BATCH_SIZE: 200
[24/04/19 11:32:00] [cifar10c_all_resemble.py:  120]: test-time adaptation: TENT
[24/04/19 11:32:00] [cifar10c_all_resemble.py:  442]: model for adaptation: DataParallel(
  (module): ResNet_SDN(
    (init_conv): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0-8): 9 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (9): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (10): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (11): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (12-14): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (15): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (16-17): 2 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (18): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (19): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (20-22): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (23): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (24-26): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
    )
    (end_layers): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)
      (1): Flatten()
      (2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)
[24/04/19 11:32:00] [cifar10c_all_resemble.py:  443]: params for adaptation: ['module.init_conv.1.weight', 'module.init_conv.1.bias', 'module.layers.0.layers.0.1.weight', 'module.layers.0.layers.0.1.bias', 'module.layers.0.layers.0.4.weight', 'module.layers.0.layers.0.4.bias', 'module.layers.1.layers.0.1.weight', 'module.layers.1.layers.0.1.bias', 'module.layers.1.layers.0.4.weight', 'module.layers.1.layers.0.4.bias', 'module.layers.2.layers.0.1.weight', 'module.layers.2.layers.0.1.bias', 'module.layers.2.layers.0.4.weight', 'module.layers.2.layers.0.4.bias', 'module.layers.3.layers.0.1.weight', 'module.layers.3.layers.0.1.bias', 'module.layers.3.layers.0.4.weight', 'module.layers.3.layers.0.4.bias', 'module.layers.4.layers.0.1.weight', 'module.layers.4.layers.0.1.bias', 'module.layers.4.layers.0.4.weight', 'module.layers.4.layers.0.4.bias', 'module.layers.5.layers.0.1.weight', 'module.layers.5.layers.0.1.bias', 'module.layers.5.layers.0.4.weight', 'module.layers.5.layers.0.4.bias', 'module.layers.6.layers.0.1.weight', 'module.layers.6.layers.0.1.bias', 'module.layers.6.layers.0.4.weight', 'module.layers.6.layers.0.4.bias', 'module.layers.7.layers.0.1.weight', 'module.layers.7.layers.0.1.bias', 'module.layers.7.layers.0.4.weight', 'module.layers.7.layers.0.4.bias', 'module.layers.8.layers.0.1.weight', 'module.layers.8.layers.0.1.bias', 'module.layers.8.layers.0.4.weight', 'module.layers.8.layers.0.4.bias', 'module.layers.9.layers.0.1.weight', 'module.layers.9.layers.0.1.bias', 'module.layers.9.layers.0.4.weight', 'module.layers.9.layers.0.4.bias', 'module.layers.9.layers.1.1.weight', 'module.layers.9.layers.1.1.bias', 'module.layers.10.layers.0.1.weight', 'module.layers.10.layers.0.1.bias', 'module.layers.10.layers.0.4.weight', 'module.layers.10.layers.0.4.bias', 'module.layers.11.layers.0.1.weight', 'module.layers.11.layers.0.1.bias', 'module.layers.11.layers.0.4.weight', 'module.layers.11.layers.0.4.bias', 'module.layers.12.layers.0.1.weight', 'module.layers.12.layers.0.1.bias', 'module.layers.12.layers.0.4.weight', 'module.layers.12.layers.0.4.bias', 'module.layers.13.layers.0.1.weight', 'module.layers.13.layers.0.1.bias', 'module.layers.13.layers.0.4.weight', 'module.layers.13.layers.0.4.bias', 'module.layers.14.layers.0.1.weight', 'module.layers.14.layers.0.1.bias', 'module.layers.14.layers.0.4.weight', 'module.layers.14.layers.0.4.bias', 'module.layers.15.layers.0.1.weight', 'module.layers.15.layers.0.1.bias', 'module.layers.15.layers.0.4.weight', 'module.layers.15.layers.0.4.bias', 'module.layers.16.layers.0.1.weight', 'module.layers.16.layers.0.1.bias', 'module.layers.16.layers.0.4.weight', 'module.layers.16.layers.0.4.bias', 'module.layers.17.layers.0.1.weight', 'module.layers.17.layers.0.1.bias', 'module.layers.17.layers.0.4.weight', 'module.layers.17.layers.0.4.bias', 'module.layers.18.layers.0.1.weight', 'module.layers.18.layers.0.1.bias', 'module.layers.18.layers.0.4.weight', 'module.layers.18.layers.0.4.bias', 'module.layers.18.layers.1.1.weight', 'module.layers.18.layers.1.1.bias', 'module.layers.19.layers.0.1.weight', 'module.layers.19.layers.0.1.bias', 'module.layers.19.layers.0.4.weight', 'module.layers.19.layers.0.4.bias', 'module.layers.20.layers.0.1.weight', 'module.layers.20.layers.0.1.bias', 'module.layers.20.layers.0.4.weight', 'module.layers.20.layers.0.4.bias', 'module.layers.21.layers.0.1.weight', 'module.layers.21.layers.0.1.bias', 'module.layers.21.layers.0.4.weight', 'module.layers.21.layers.0.4.bias', 'module.layers.22.layers.0.1.weight', 'module.layers.22.layers.0.1.bias', 'module.layers.22.layers.0.4.weight', 'module.layers.22.layers.0.4.bias', 'module.layers.23.layers.0.1.weight', 'module.layers.23.layers.0.1.bias', 'module.layers.23.layers.0.4.weight', 'module.layers.23.layers.0.4.bias', 'module.layers.24.layers.0.1.weight', 'module.layers.24.layers.0.1.bias', 'module.layers.24.layers.0.4.weight', 'module.layers.24.layers.0.4.bias', 'module.layers.25.layers.0.1.weight', 'module.layers.25.layers.0.1.bias', 'module.layers.25.layers.0.4.weight', 'module.layers.25.layers.0.4.bias', 'module.layers.26.layers.0.1.weight', 'module.layers.26.layers.0.1.bias', 'module.layers.26.layers.0.4.weight', 'module.layers.26.layers.0.4.bias']
[24/04/19 11:32:00] [cifar10c_all_resemble.py:  444]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.0
)
[24/04/19 11:32:10] [cifar10c_all_resemble.py:  284]: error % [gaussian_noise5]: 33.99%
[24/04/19 11:32:18] [cifar10c_all_resemble.py:  284]: error % [shot_noise5]: 31.69%
[24/04/19 11:32:38] [cifar10c_all_resemble.py:  284]: error % [impulse_noise5]: 39.03%
[24/04/19 11:32:47] [cifar10c_all_resemble.py:  284]: error % [defocus_blur5]: 15.56%
[24/04/19 11:32:56] [cifar10c_all_resemble.py:  284]: error % [glass_blur5]: 38.45%
[24/04/19 11:33:05] [cifar10c_all_resemble.py:  284]: error % [motion_blur5]: 17.27%
[24/04/19 11:33:25] [cifar10c_all_resemble.py:  284]: error % [zoom_blur5]: 16.90%
[24/04/19 11:33:31] [cifar10c_all_resemble.py:  284]: error % [snow5]: 22.35%
[24/04/19 11:33:38] [cifar10c_all_resemble.py:  284]: error % [frost5]: 23.21%
[24/04/19 11:33:44] [cifar10c_all_resemble.py:  284]: error % [fog5]: 17.51%
[24/04/19 11:33:55] [cifar10c_all_resemble.py:  284]: error % [brightness5]: 11.71%
[24/04/19 11:34:09] [cifar10c_all_resemble.py:  284]: error % [contrast5]: 19.12%
[24/04/19 11:34:15] [cifar10c_all_resemble.py:  284]: error % [elastic_transform5]: 26.70%
[24/04/19 11:34:22] [cifar10c_all_resemble.py:  284]: error % [pixelate5]: 25.49%
[24/04/19 11:34:28] [cifar10c_all_resemble.py:  284]: error % [jpeg_compression5]: 29.67%
[24/04/19 11:34:28] [cifar10c_all_resemble.py:  287]: error % [mean5]: 24.58%
[24/04/19 11:52:21] [conf.py:  213]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: tent_Adam_1e-05_bs200_em0.2.txt
LOG_TIME: 240419_115221
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 1e-05
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RESET_CONSTANT_EM: 0.2
RNG_SEED: 1
SAVE_DIR: ./output2
TEST:
  BATCH_SIZE: 200
[24/04/19 11:52:21] [cifar10c_all_resemble.py:  120]: test-time adaptation: TENT
[24/04/19 11:52:21] [cifar10c_all_resemble.py:  442]: model for adaptation: DataParallel(
  (module): ResNet_SDN(
    (init_conv): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0-8): 9 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (9): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (10): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (11): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (12-14): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (15): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (16-17): 2 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (18): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (19): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (20-22): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (23): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (24-26): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
    )
    (end_layers): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)
      (1): Flatten()
      (2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)
[24/04/19 11:52:21] [cifar10c_all_resemble.py:  443]: params for adaptation: ['module.init_conv.1.weight', 'module.init_conv.1.bias', 'module.layers.0.layers.0.1.weight', 'module.layers.0.layers.0.1.bias', 'module.layers.0.layers.0.4.weight', 'module.layers.0.layers.0.4.bias', 'module.layers.1.layers.0.1.weight', 'module.layers.1.layers.0.1.bias', 'module.layers.1.layers.0.4.weight', 'module.layers.1.layers.0.4.bias', 'module.layers.2.layers.0.1.weight', 'module.layers.2.layers.0.1.bias', 'module.layers.2.layers.0.4.weight', 'module.layers.2.layers.0.4.bias', 'module.layers.3.layers.0.1.weight', 'module.layers.3.layers.0.1.bias', 'module.layers.3.layers.0.4.weight', 'module.layers.3.layers.0.4.bias', 'module.layers.4.layers.0.1.weight', 'module.layers.4.layers.0.1.bias', 'module.layers.4.layers.0.4.weight', 'module.layers.4.layers.0.4.bias', 'module.layers.5.layers.0.1.weight', 'module.layers.5.layers.0.1.bias', 'module.layers.5.layers.0.4.weight', 'module.layers.5.layers.0.4.bias', 'module.layers.6.layers.0.1.weight', 'module.layers.6.layers.0.1.bias', 'module.layers.6.layers.0.4.weight', 'module.layers.6.layers.0.4.bias', 'module.layers.7.layers.0.1.weight', 'module.layers.7.layers.0.1.bias', 'module.layers.7.layers.0.4.weight', 'module.layers.7.layers.0.4.bias', 'module.layers.8.layers.0.1.weight', 'module.layers.8.layers.0.1.bias', 'module.layers.8.layers.0.4.weight', 'module.layers.8.layers.0.4.bias', 'module.layers.9.layers.0.1.weight', 'module.layers.9.layers.0.1.bias', 'module.layers.9.layers.0.4.weight', 'module.layers.9.layers.0.4.bias', 'module.layers.9.layers.1.1.weight', 'module.layers.9.layers.1.1.bias', 'module.layers.10.layers.0.1.weight', 'module.layers.10.layers.0.1.bias', 'module.layers.10.layers.0.4.weight', 'module.layers.10.layers.0.4.bias', 'module.layers.11.layers.0.1.weight', 'module.layers.11.layers.0.1.bias', 'module.layers.11.layers.0.4.weight', 'module.layers.11.layers.0.4.bias', 'module.layers.12.layers.0.1.weight', 'module.layers.12.layers.0.1.bias', 'module.layers.12.layers.0.4.weight', 'module.layers.12.layers.0.4.bias', 'module.layers.13.layers.0.1.weight', 'module.layers.13.layers.0.1.bias', 'module.layers.13.layers.0.4.weight', 'module.layers.13.layers.0.4.bias', 'module.layers.14.layers.0.1.weight', 'module.layers.14.layers.0.1.bias', 'module.layers.14.layers.0.4.weight', 'module.layers.14.layers.0.4.bias', 'module.layers.15.layers.0.1.weight', 'module.layers.15.layers.0.1.bias', 'module.layers.15.layers.0.4.weight', 'module.layers.15.layers.0.4.bias', 'module.layers.16.layers.0.1.weight', 'module.layers.16.layers.0.1.bias', 'module.layers.16.layers.0.4.weight', 'module.layers.16.layers.0.4.bias', 'module.layers.17.layers.0.1.weight', 'module.layers.17.layers.0.1.bias', 'module.layers.17.layers.0.4.weight', 'module.layers.17.layers.0.4.bias', 'module.layers.18.layers.0.1.weight', 'module.layers.18.layers.0.1.bias', 'module.layers.18.layers.0.4.weight', 'module.layers.18.layers.0.4.bias', 'module.layers.18.layers.1.1.weight', 'module.layers.18.layers.1.1.bias', 'module.layers.19.layers.0.1.weight', 'module.layers.19.layers.0.1.bias', 'module.layers.19.layers.0.4.weight', 'module.layers.19.layers.0.4.bias', 'module.layers.20.layers.0.1.weight', 'module.layers.20.layers.0.1.bias', 'module.layers.20.layers.0.4.weight', 'module.layers.20.layers.0.4.bias', 'module.layers.21.layers.0.1.weight', 'module.layers.21.layers.0.1.bias', 'module.layers.21.layers.0.4.weight', 'module.layers.21.layers.0.4.bias', 'module.layers.22.layers.0.1.weight', 'module.layers.22.layers.0.1.bias', 'module.layers.22.layers.0.4.weight', 'module.layers.22.layers.0.4.bias', 'module.layers.23.layers.0.1.weight', 'module.layers.23.layers.0.1.bias', 'module.layers.23.layers.0.4.weight', 'module.layers.23.layers.0.4.bias', 'module.layers.24.layers.0.1.weight', 'module.layers.24.layers.0.1.bias', 'module.layers.24.layers.0.4.weight', 'module.layers.24.layers.0.4.bias', 'module.layers.25.layers.0.1.weight', 'module.layers.25.layers.0.1.bias', 'module.layers.25.layers.0.4.weight', 'module.layers.25.layers.0.4.bias', 'module.layers.26.layers.0.1.weight', 'module.layers.26.layers.0.1.bias', 'module.layers.26.layers.0.4.weight', 'module.layers.26.layers.0.4.bias']
[24/04/19 11:52:21] [cifar10c_all_resemble.py:  444]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.0
)
[24/04/19 11:52:29] [cifar10c_all_resemble.py:  284]: error % [gaussian_noise5]: 36.05%
[24/04/19 11:52:46] [cifar10c_all_resemble.py:  284]: error % [shot_noise5]: 33.95%
[24/04/19 11:52:54] [cifar10c_all_resemble.py:  284]: error % [impulse_noise5]: 41.38%
[24/04/19 11:53:01] [cifar10c_all_resemble.py:  284]: error % [defocus_blur5]: 15.35%
[24/04/19 11:53:07] [cifar10c_all_resemble.py:  284]: error % [glass_blur5]: 40.08%
[24/04/19 11:53:13] [cifar10c_all_resemble.py:  284]: error % [motion_blur5]: 17.18%
[24/04/19 11:53:33] [cifar10c_all_resemble.py:  284]: error % [zoom_blur5]: 16.50%
[24/04/19 11:53:39] [cifar10c_all_resemble.py:  284]: error % [snow5]: 21.77%
[24/04/19 11:53:46] [cifar10c_all_resemble.py:  284]: error % [frost5]: 23.62%
[24/04/19 11:53:51] [cifar10c_all_resemble.py:  284]: error % [fog5]: 17.61%
[24/04/19 11:54:05] [cifar10c_all_resemble.py:  284]: error % [brightness5]: 11.24%
[24/04/19 11:54:17] [cifar10c_all_resemble.py:  284]: error % [contrast5]: 18.37%
[24/04/19 11:54:23] [cifar10c_all_resemble.py:  284]: error % [elastic_transform5]: 26.77%
[24/04/19 11:54:30] [cifar10c_all_resemble.py:  284]: error % [pixelate5]: 26.07%
[24/04/19 11:54:36] [cifar10c_all_resemble.py:  284]: error % [jpeg_compression5]: 29.88%
[24/04/19 11:54:36] [cifar10c_all_resemble.py:  287]: error % [mean5]: 25.05%
[24/04/19 11:55:36] [conf.py:  213]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: tent_Adam_1e-05_bs200_em0.2.txt
LOG_TIME: 240419_115536
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 1e-05
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RESET_CONSTANT_EM: 0.2
RNG_SEED: 1
SAVE_DIR: ./output2
TEST:
  BATCH_SIZE: 200
[24/04/19 11:55:36] [cifar10c_all_resemble.py:  120]: test-time adaptation: TENT
[24/04/19 11:55:36] [cifar10c_all_resemble.py:  442]: model for adaptation: DataParallel(
  (module): ResNet_SDN(
    (init_conv): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0-8): 9 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (9): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (10): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (11): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (12-14): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (15): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (16-17): 2 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (18): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (19): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (20-22): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (23): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (24-26): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
    )
    (end_layers): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)
      (1): Flatten()
      (2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)
[24/04/19 11:55:36] [cifar10c_all_resemble.py:  443]: params for adaptation: ['module.init_conv.1.weight', 'module.init_conv.1.bias', 'module.layers.0.layers.0.1.weight', 'module.layers.0.layers.0.1.bias', 'module.layers.0.layers.0.4.weight', 'module.layers.0.layers.0.4.bias', 'module.layers.1.layers.0.1.weight', 'module.layers.1.layers.0.1.bias', 'module.layers.1.layers.0.4.weight', 'module.layers.1.layers.0.4.bias', 'module.layers.2.layers.0.1.weight', 'module.layers.2.layers.0.1.bias', 'module.layers.2.layers.0.4.weight', 'module.layers.2.layers.0.4.bias', 'module.layers.3.layers.0.1.weight', 'module.layers.3.layers.0.1.bias', 'module.layers.3.layers.0.4.weight', 'module.layers.3.layers.0.4.bias', 'module.layers.4.layers.0.1.weight', 'module.layers.4.layers.0.1.bias', 'module.layers.4.layers.0.4.weight', 'module.layers.4.layers.0.4.bias', 'module.layers.5.layers.0.1.weight', 'module.layers.5.layers.0.1.bias', 'module.layers.5.layers.0.4.weight', 'module.layers.5.layers.0.4.bias', 'module.layers.6.layers.0.1.weight', 'module.layers.6.layers.0.1.bias', 'module.layers.6.layers.0.4.weight', 'module.layers.6.layers.0.4.bias', 'module.layers.7.layers.0.1.weight', 'module.layers.7.layers.0.1.bias', 'module.layers.7.layers.0.4.weight', 'module.layers.7.layers.0.4.bias', 'module.layers.8.layers.0.1.weight', 'module.layers.8.layers.0.1.bias', 'module.layers.8.layers.0.4.weight', 'module.layers.8.layers.0.4.bias', 'module.layers.9.layers.0.1.weight', 'module.layers.9.layers.0.1.bias', 'module.layers.9.layers.0.4.weight', 'module.layers.9.layers.0.4.bias', 'module.layers.9.layers.1.1.weight', 'module.layers.9.layers.1.1.bias', 'module.layers.10.layers.0.1.weight', 'module.layers.10.layers.0.1.bias', 'module.layers.10.layers.0.4.weight', 'module.layers.10.layers.0.4.bias', 'module.layers.11.layers.0.1.weight', 'module.layers.11.layers.0.1.bias', 'module.layers.11.layers.0.4.weight', 'module.layers.11.layers.0.4.bias', 'module.layers.12.layers.0.1.weight', 'module.layers.12.layers.0.1.bias', 'module.layers.12.layers.0.4.weight', 'module.layers.12.layers.0.4.bias', 'module.layers.13.layers.0.1.weight', 'module.layers.13.layers.0.1.bias', 'module.layers.13.layers.0.4.weight', 'module.layers.13.layers.0.4.bias', 'module.layers.14.layers.0.1.weight', 'module.layers.14.layers.0.1.bias', 'module.layers.14.layers.0.4.weight', 'module.layers.14.layers.0.4.bias', 'module.layers.15.layers.0.1.weight', 'module.layers.15.layers.0.1.bias', 'module.layers.15.layers.0.4.weight', 'module.layers.15.layers.0.4.bias', 'module.layers.16.layers.0.1.weight', 'module.layers.16.layers.0.1.bias', 'module.layers.16.layers.0.4.weight', 'module.layers.16.layers.0.4.bias', 'module.layers.17.layers.0.1.weight', 'module.layers.17.layers.0.1.bias', 'module.layers.17.layers.0.4.weight', 'module.layers.17.layers.0.4.bias', 'module.layers.18.layers.0.1.weight', 'module.layers.18.layers.0.1.bias', 'module.layers.18.layers.0.4.weight', 'module.layers.18.layers.0.4.bias', 'module.layers.18.layers.1.1.weight', 'module.layers.18.layers.1.1.bias', 'module.layers.19.layers.0.1.weight', 'module.layers.19.layers.0.1.bias', 'module.layers.19.layers.0.4.weight', 'module.layers.19.layers.0.4.bias', 'module.layers.20.layers.0.1.weight', 'module.layers.20.layers.0.1.bias', 'module.layers.20.layers.0.4.weight', 'module.layers.20.layers.0.4.bias', 'module.layers.21.layers.0.1.weight', 'module.layers.21.layers.0.1.bias', 'module.layers.21.layers.0.4.weight', 'module.layers.21.layers.0.4.bias', 'module.layers.22.layers.0.1.weight', 'module.layers.22.layers.0.1.bias', 'module.layers.22.layers.0.4.weight', 'module.layers.22.layers.0.4.bias', 'module.layers.23.layers.0.1.weight', 'module.layers.23.layers.0.1.bias', 'module.layers.23.layers.0.4.weight', 'module.layers.23.layers.0.4.bias', 'module.layers.24.layers.0.1.weight', 'module.layers.24.layers.0.1.bias', 'module.layers.24.layers.0.4.weight', 'module.layers.24.layers.0.4.bias', 'module.layers.25.layers.0.1.weight', 'module.layers.25.layers.0.1.bias', 'module.layers.25.layers.0.4.weight', 'module.layers.25.layers.0.4.bias', 'module.layers.26.layers.0.1.weight', 'module.layers.26.layers.0.1.bias', 'module.layers.26.layers.0.4.weight', 'module.layers.26.layers.0.4.bias']
[24/04/19 11:55:36] [cifar10c_all_resemble.py:  444]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.0
)
[24/04/19 11:55:51] [cifar10c_all_resemble.py:  284]: error % [gaussian_noise5]: 36.31%
[24/04/19 11:56:04] [cifar10c_all_resemble.py:  284]: error % [shot_noise5]: 34.17%
[24/04/19 11:56:10] [cifar10c_all_resemble.py:  284]: error % [impulse_noise5]: 41.70%
[24/04/19 11:56:16] [cifar10c_all_resemble.py:  284]: error % [defocus_blur5]: 15.42%
[24/04/19 11:56:22] [cifar10c_all_resemble.py:  284]: error % [glass_blur5]: 40.07%
[24/04/19 11:56:42] [cifar10c_all_resemble.py:  284]: error % [motion_blur5]: 17.35%
[24/04/19 11:56:48] [cifar10c_all_resemble.py:  284]: error % [zoom_blur5]: 16.64%
[24/04/19 11:56:54] [cifar10c_all_resemble.py:  284]: error % [snow5]: 21.83%
[24/04/19 11:57:00] [cifar10c_all_resemble.py:  284]: error % [frost5]: 23.81%
[24/04/19 11:57:13] [cifar10c_all_resemble.py:  284]: error % [fog5]: 17.76%
[24/04/19 11:57:26] [cifar10c_all_resemble.py:  284]: error % [brightness5]: 11.51%
[24/04/19 11:57:32] [cifar10c_all_resemble.py:  284]: error % [contrast5]: 18.49%
[24/04/19 11:57:39] [cifar10c_all_resemble.py:  284]: error % [elastic_transform5]: 26.99%
[24/04/19 11:57:44] [cifar10c_all_resemble.py:  284]: error % [pixelate5]: 26.24%
[24/04/19 11:58:03] [cifar10c_all_resemble.py:  284]: error % [jpeg_compression5]: 30.30%
[24/04/19 11:58:03] [cifar10c_all_resemble.py:  287]: error % [mean5]: 25.24%
[24/04/19 13:46:30] [conf.py:  213]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: tent_Adam_1e-05_bs200_em0.2.txt
LOG_TIME: 240419_134630
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 1e-05
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RESET_CONSTANT_EM: 0.2
RNG_SEED: 1
SAVE_DIR: ./output2
TEST:
  BATCH_SIZE: 200
[24/04/19 13:46:30] [cifar10c_all_resemble.py:  120]: test-time adaptation: TENT
[24/04/19 13:46:30] [cifar10c_all_resemble.py:  443]: model for adaptation: DataParallel(
  (module): ResNet_SDN(
    (init_conv): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0-8): 9 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (9): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (10): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (11): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (12-14): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (15): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (16-17): 2 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (18): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (19): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (20-22): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (23): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (24-26): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
    )
    (end_layers): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)
      (1): Flatten()
      (2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)
[24/04/19 13:46:30] [cifar10c_all_resemble.py:  444]: params for adaptation: ['module.init_conv.1.weight', 'module.init_conv.1.bias', 'module.layers.0.layers.0.1.weight', 'module.layers.0.layers.0.1.bias', 'module.layers.0.layers.0.4.weight', 'module.layers.0.layers.0.4.bias', 'module.layers.1.layers.0.1.weight', 'module.layers.1.layers.0.1.bias', 'module.layers.1.layers.0.4.weight', 'module.layers.1.layers.0.4.bias', 'module.layers.2.layers.0.1.weight', 'module.layers.2.layers.0.1.bias', 'module.layers.2.layers.0.4.weight', 'module.layers.2.layers.0.4.bias', 'module.layers.3.layers.0.1.weight', 'module.layers.3.layers.0.1.bias', 'module.layers.3.layers.0.4.weight', 'module.layers.3.layers.0.4.bias', 'module.layers.4.layers.0.1.weight', 'module.layers.4.layers.0.1.bias', 'module.layers.4.layers.0.4.weight', 'module.layers.4.layers.0.4.bias', 'module.layers.5.layers.0.1.weight', 'module.layers.5.layers.0.1.bias', 'module.layers.5.layers.0.4.weight', 'module.layers.5.layers.0.4.bias', 'module.layers.6.layers.0.1.weight', 'module.layers.6.layers.0.1.bias', 'module.layers.6.layers.0.4.weight', 'module.layers.6.layers.0.4.bias', 'module.layers.7.layers.0.1.weight', 'module.layers.7.layers.0.1.bias', 'module.layers.7.layers.0.4.weight', 'module.layers.7.layers.0.4.bias', 'module.layers.8.layers.0.1.weight', 'module.layers.8.layers.0.1.bias', 'module.layers.8.layers.0.4.weight', 'module.layers.8.layers.0.4.bias', 'module.layers.9.layers.0.1.weight', 'module.layers.9.layers.0.1.bias', 'module.layers.9.layers.0.4.weight', 'module.layers.9.layers.0.4.bias', 'module.layers.9.layers.1.1.weight', 'module.layers.9.layers.1.1.bias', 'module.layers.10.layers.0.1.weight', 'module.layers.10.layers.0.1.bias', 'module.layers.10.layers.0.4.weight', 'module.layers.10.layers.0.4.bias', 'module.layers.11.layers.0.1.weight', 'module.layers.11.layers.0.1.bias', 'module.layers.11.layers.0.4.weight', 'module.layers.11.layers.0.4.bias', 'module.layers.12.layers.0.1.weight', 'module.layers.12.layers.0.1.bias', 'module.layers.12.layers.0.4.weight', 'module.layers.12.layers.0.4.bias', 'module.layers.13.layers.0.1.weight', 'module.layers.13.layers.0.1.bias', 'module.layers.13.layers.0.4.weight', 'module.layers.13.layers.0.4.bias', 'module.layers.14.layers.0.1.weight', 'module.layers.14.layers.0.1.bias', 'module.layers.14.layers.0.4.weight', 'module.layers.14.layers.0.4.bias', 'module.layers.15.layers.0.1.weight', 'module.layers.15.layers.0.1.bias', 'module.layers.15.layers.0.4.weight', 'module.layers.15.layers.0.4.bias', 'module.layers.16.layers.0.1.weight', 'module.layers.16.layers.0.1.bias', 'module.layers.16.layers.0.4.weight', 'module.layers.16.layers.0.4.bias', 'module.layers.17.layers.0.1.weight', 'module.layers.17.layers.0.1.bias', 'module.layers.17.layers.0.4.weight', 'module.layers.17.layers.0.4.bias', 'module.layers.18.layers.0.1.weight', 'module.layers.18.layers.0.1.bias', 'module.layers.18.layers.0.4.weight', 'module.layers.18.layers.0.4.bias', 'module.layers.18.layers.1.1.weight', 'module.layers.18.layers.1.1.bias', 'module.layers.19.layers.0.1.weight', 'module.layers.19.layers.0.1.bias', 'module.layers.19.layers.0.4.weight', 'module.layers.19.layers.0.4.bias', 'module.layers.20.layers.0.1.weight', 'module.layers.20.layers.0.1.bias', 'module.layers.20.layers.0.4.weight', 'module.layers.20.layers.0.4.bias', 'module.layers.21.layers.0.1.weight', 'module.layers.21.layers.0.1.bias', 'module.layers.21.layers.0.4.weight', 'module.layers.21.layers.0.4.bias', 'module.layers.22.layers.0.1.weight', 'module.layers.22.layers.0.1.bias', 'module.layers.22.layers.0.4.weight', 'module.layers.22.layers.0.4.bias', 'module.layers.23.layers.0.1.weight', 'module.layers.23.layers.0.1.bias', 'module.layers.23.layers.0.4.weight', 'module.layers.23.layers.0.4.bias', 'module.layers.24.layers.0.1.weight', 'module.layers.24.layers.0.1.bias', 'module.layers.24.layers.0.4.weight', 'module.layers.24.layers.0.4.bias', 'module.layers.25.layers.0.1.weight', 'module.layers.25.layers.0.1.bias', 'module.layers.25.layers.0.4.weight', 'module.layers.25.layers.0.4.bias', 'module.layers.26.layers.0.1.weight', 'module.layers.26.layers.0.1.bias', 'module.layers.26.layers.0.4.weight', 'module.layers.26.layers.0.4.bias']
[24/04/19 13:46:30] [cifar10c_all_resemble.py:  445]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.0
)
[24/04/19 13:46:38] [cifar10c_all_resemble.py:  285]: error % [gaussian_noise5]: 38.00%
[24/04/19 13:46:44] [cifar10c_all_resemble.py:  285]: error % [shot_noise5]: 35.93%
[24/04/19 13:46:49] [cifar10c_all_resemble.py:  285]: error % [impulse_noise5]: 43.75%
[24/04/19 13:46:55] [cifar10c_all_resemble.py:  285]: error % [defocus_blur5]: 16.19%
[24/04/19 13:47:02] [cifar10c_all_resemble.py:  285]: error % [glass_blur5]: 41.75%
[24/04/19 13:47:07] [cifar10c_all_resemble.py:  285]: error % [motion_blur5]: 18.00%
[24/04/19 13:47:14] [cifar10c_all_resemble.py:  285]: error % [zoom_blur5]: 17.35%
[24/04/19 13:47:22] [cifar10c_all_resemble.py:  285]: error % [snow5]: 22.50%
[24/04/19 13:47:31] [cifar10c_all_resemble.py:  285]: error % [frost5]: 24.68%
[24/04/19 13:47:40] [cifar10c_all_resemble.py:  285]: error % [fog5]: 18.65%
[24/04/19 13:47:48] [cifar10c_all_resemble.py:  285]: error % [brightness5]: 12.02%
[24/04/19 13:47:57] [cifar10c_all_resemble.py:  285]: error % [contrast5]: 19.15%
[24/04/19 13:48:06] [cifar10c_all_resemble.py:  285]: error % [elastic_transform5]: 28.05%
[24/04/19 13:48:14] [cifar10c_all_resemble.py:  285]: error % [pixelate5]: 27.15%
[24/04/19 13:48:23] [cifar10c_all_resemble.py:  285]: error % [jpeg_compression5]: 31.86%
[24/04/19 13:48:23] [cifar10c_all_resemble.py:  288]: error % [mean5]: 26.34%
[24/04/19 13:50:38] [conf.py:  213]: BN:
  EPS: 1e-05
  MOM: 0.1
CKPT_DIR: ./ckpt
CORRUPTION:
  DATASET: cifar10
  NUM_EX: 10000
  SEVERITY: [5]
  TYPE: ['gaussian_noise', 'shot_noise', 'impulse_noise', 'defocus_blur', 'glass_blur', 'motion_blur', 'zoom_blur', 'snow', 'frost', 'fog', 'brightness', 'contrast', 'elastic_transform', 'pixelate', 'jpeg_compression']
CUDNN:
  BENCHMARK: True
DATA_DIR: ./data
DESC: 
LOG_DEST: tent_Adam_1e-05_bs200_em0.2.txt
LOG_TIME: 240419_135038
MODEL:
  ADAPTATION: tent
  ARCH: Standard
  EPISODIC: False
OPTIM:
  BETA: 0.9
  DAMPENING: 0.0
  LR: 1e-05
  METHOD: Adam
  MOMENTUM: 0.9
  NESTEROV: True
  STEPS: 1
  WD: 0.0
RESET_CONSTANT_EM: 0.2
RNG_SEED: 1
SAVE_DIR: ./output2
TEST:
  BATCH_SIZE: 200
[24/04/19 13:50:38] [cifar10c_all_resemble.py:  120]: test-time adaptation: TENT
[24/04/19 13:50:38] [cifar10c_all_resemble.py:  443]: model for adaptation: DataParallel(
  (module): ResNet_SDN(
    (init_conv): Sequential(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (2): ReLU()
    )
    (layers): ModuleList(
      (0-8): 9 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (9): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (10): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (11): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (12-14): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (15): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)
          (linear): Linear(in_features=512, out_features=10, bias=True)
        )
      )
      (16-17): 2 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (18): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential(
            (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (2): ReLU()
        )
      )
      (19): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (20-22): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
      (23): BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
        (output): InternalClassifier(
          (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
          (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
          (linear): Linear(in_features=1024, out_features=10, bias=True)
        )
      )
      (24-26): 3 x BasicBlockWOutput(
        (layers): ModuleList(
          (0): Sequential(
            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (2): ReLU()
            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          )
          (1): Sequential()
          (2): ReLU()
        )
      )
    )
    (end_layers): Sequential(
      (0): AvgPool2d(kernel_size=8, stride=8, padding=0)
      (1): Flatten()
      (2): Linear(in_features=64, out_features=10, bias=True)
    )
  )
)
[24/04/19 13:50:38] [cifar10c_all_resemble.py:  444]: params for adaptation: ['module.init_conv.1.weight', 'module.init_conv.1.bias', 'module.layers.0.layers.0.1.weight', 'module.layers.0.layers.0.1.bias', 'module.layers.0.layers.0.4.weight', 'module.layers.0.layers.0.4.bias', 'module.layers.1.layers.0.1.weight', 'module.layers.1.layers.0.1.bias', 'module.layers.1.layers.0.4.weight', 'module.layers.1.layers.0.4.bias', 'module.layers.2.layers.0.1.weight', 'module.layers.2.layers.0.1.bias', 'module.layers.2.layers.0.4.weight', 'module.layers.2.layers.0.4.bias', 'module.layers.3.layers.0.1.weight', 'module.layers.3.layers.0.1.bias', 'module.layers.3.layers.0.4.weight', 'module.layers.3.layers.0.4.bias', 'module.layers.4.layers.0.1.weight', 'module.layers.4.layers.0.1.bias', 'module.layers.4.layers.0.4.weight', 'module.layers.4.layers.0.4.bias', 'module.layers.5.layers.0.1.weight', 'module.layers.5.layers.0.1.bias', 'module.layers.5.layers.0.4.weight', 'module.layers.5.layers.0.4.bias', 'module.layers.6.layers.0.1.weight', 'module.layers.6.layers.0.1.bias', 'module.layers.6.layers.0.4.weight', 'module.layers.6.layers.0.4.bias', 'module.layers.7.layers.0.1.weight', 'module.layers.7.layers.0.1.bias', 'module.layers.7.layers.0.4.weight', 'module.layers.7.layers.0.4.bias', 'module.layers.8.layers.0.1.weight', 'module.layers.8.layers.0.1.bias', 'module.layers.8.layers.0.4.weight', 'module.layers.8.layers.0.4.bias', 'module.layers.9.layers.0.1.weight', 'module.layers.9.layers.0.1.bias', 'module.layers.9.layers.0.4.weight', 'module.layers.9.layers.0.4.bias', 'module.layers.9.layers.1.1.weight', 'module.layers.9.layers.1.1.bias', 'module.layers.10.layers.0.1.weight', 'module.layers.10.layers.0.1.bias', 'module.layers.10.layers.0.4.weight', 'module.layers.10.layers.0.4.bias', 'module.layers.11.layers.0.1.weight', 'module.layers.11.layers.0.1.bias', 'module.layers.11.layers.0.4.weight', 'module.layers.11.layers.0.4.bias', 'module.layers.12.layers.0.1.weight', 'module.layers.12.layers.0.1.bias', 'module.layers.12.layers.0.4.weight', 'module.layers.12.layers.0.4.bias', 'module.layers.13.layers.0.1.weight', 'module.layers.13.layers.0.1.bias', 'module.layers.13.layers.0.4.weight', 'module.layers.13.layers.0.4.bias', 'module.layers.14.layers.0.1.weight', 'module.layers.14.layers.0.1.bias', 'module.layers.14.layers.0.4.weight', 'module.layers.14.layers.0.4.bias', 'module.layers.15.layers.0.1.weight', 'module.layers.15.layers.0.1.bias', 'module.layers.15.layers.0.4.weight', 'module.layers.15.layers.0.4.bias', 'module.layers.16.layers.0.1.weight', 'module.layers.16.layers.0.1.bias', 'module.layers.16.layers.0.4.weight', 'module.layers.16.layers.0.4.bias', 'module.layers.17.layers.0.1.weight', 'module.layers.17.layers.0.1.bias', 'module.layers.17.layers.0.4.weight', 'module.layers.17.layers.0.4.bias', 'module.layers.18.layers.0.1.weight', 'module.layers.18.layers.0.1.bias', 'module.layers.18.layers.0.4.weight', 'module.layers.18.layers.0.4.bias', 'module.layers.18.layers.1.1.weight', 'module.layers.18.layers.1.1.bias', 'module.layers.19.layers.0.1.weight', 'module.layers.19.layers.0.1.bias', 'module.layers.19.layers.0.4.weight', 'module.layers.19.layers.0.4.bias', 'module.layers.20.layers.0.1.weight', 'module.layers.20.layers.0.1.bias', 'module.layers.20.layers.0.4.weight', 'module.layers.20.layers.0.4.bias', 'module.layers.21.layers.0.1.weight', 'module.layers.21.layers.0.1.bias', 'module.layers.21.layers.0.4.weight', 'module.layers.21.layers.0.4.bias', 'module.layers.22.layers.0.1.weight', 'module.layers.22.layers.0.1.bias', 'module.layers.22.layers.0.4.weight', 'module.layers.22.layers.0.4.bias', 'module.layers.23.layers.0.1.weight', 'module.layers.23.layers.0.1.bias', 'module.layers.23.layers.0.4.weight', 'module.layers.23.layers.0.4.bias', 'module.layers.24.layers.0.1.weight', 'module.layers.24.layers.0.1.bias', 'module.layers.24.layers.0.4.weight', 'module.layers.24.layers.0.4.bias', 'module.layers.25.layers.0.1.weight', 'module.layers.25.layers.0.1.bias', 'module.layers.25.layers.0.4.weight', 'module.layers.25.layers.0.4.bias', 'module.layers.26.layers.0.1.weight', 'module.layers.26.layers.0.1.bias', 'module.layers.26.layers.0.4.weight', 'module.layers.26.layers.0.4.bias']
[24/04/19 13:50:38] [cifar10c_all_resemble.py:  445]: optimizer for adaptation: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 1e-05
    maximize: False
    weight_decay: 0.0
)
[24/04/19 13:50:47] [cifar10c_all_resemble.py:  285]: error % [gaussian_noise5]: 38.01%
[24/04/19 13:50:53] [cifar10c_all_resemble.py:  285]: error % [shot_noise5]: 35.92%
[24/04/19 13:50:59] [cifar10c_all_resemble.py:  285]: error % [impulse_noise5]: 43.75%
[24/04/19 13:51:05] [cifar10c_all_resemble.py:  285]: error % [defocus_blur5]: 16.16%
[24/04/19 13:51:11] [cifar10c_all_resemble.py:  285]: error % [glass_blur5]: 41.75%
[24/04/19 13:51:16] [cifar10c_all_resemble.py:  285]: error % [motion_blur5]: 17.99%
[24/04/19 13:51:22] [cifar10c_all_resemble.py:  285]: error % [zoom_blur5]: 17.33%
[24/04/19 13:51:28] [cifar10c_all_resemble.py:  285]: error % [snow5]: 22.52%
[24/04/19 13:51:34] [cifar10c_all_resemble.py:  285]: error % [frost5]: 24.67%
[24/04/19 13:51:40] [cifar10c_all_resemble.py:  285]: error % [fog5]: 18.64%
[24/04/19 13:51:45] [cifar10c_all_resemble.py:  285]: error % [brightness5]: 12.03%
[24/04/19 13:51:51] [cifar10c_all_resemble.py:  285]: error % [contrast5]: 19.16%
[24/04/19 13:51:57] [cifar10c_all_resemble.py:  285]: error % [elastic_transform5]: 28.03%
[24/04/19 13:52:03] [cifar10c_all_resemble.py:  285]: error % [pixelate5]: 27.15%
[24/04/19 13:52:09] [cifar10c_all_resemble.py:  285]: error % [jpeg_compression5]: 31.83%
[24/04/19 13:52:09] [cifar10c_all_resemble.py:  288]: error % [mean5]: 26.33%
